{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt # for data visualization purposes\n",
    "import seaborn as sns # for statistical data visualization\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file\n",
    "file_path = 'iris.csv'\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 5)"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View dimensions of dataset\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View top 5 rows of dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   sepal length  150 non-null    float64\n",
      " 1   sepal width   150 non-null    float64\n",
      " 2   petal length  150 non-null    float64\n",
      " 3   petal width   150 non-null    float64\n",
      " 4   class         150 non-null    object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 6.0+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(   sepal length  sepal width  petal length  petal width        class\n",
       " 0           5.1          3.5           1.4          0.2  Iris-setosa\n",
       " 1           4.9          3.0           1.4          0.2  Iris-setosa\n",
       " 2           4.7          3.2           1.3          0.2  Iris-setosa\n",
       " 3           4.6          3.1           1.5          0.2  Iris-setosa\n",
       " 4           5.0          3.6           1.4          0.2  Iris-setosa,\n",
       " None)"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first few rows of the dataset to understand its structure\n",
    "df.head(), df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 categorical variables\n",
      "\n",
      "The categorical variables are :\n",
      "\n",
      " ['class']\n"
     ]
    }
   ],
   "source": [
    "# Explore categorical variables\n",
    "categorical = [var for var in df.columns if df[var].dtype=='O']\n",
    "\n",
    "print('There are {} categorical variables\\n'.format(len(categorical)))\n",
    "print('The categorical variables are :\\n\\n', categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         class\n",
       "0  Iris-setosa\n",
       "1  Iris-setosa\n",
       "2  Iris-setosa\n",
       "3  Iris-setosa\n",
       "4  Iris-setosa"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the categorical variables\n",
    "df[categorical].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore problems within categorical variables\n",
    "First, I will explore the categorical variables.\n",
    "\n",
    "Missing values in categorical variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check missing values in categorical variables\n",
    "df[categorical].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class\n",
      "Iris-setosa        50\n",
      "Iris-versicolor    50\n",
      "Iris-virginica     50\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# View frequency counts of values in categorical variables\n",
    "for var in categorical: \n",
    "    print(df[var].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class\n",
      "Iris-setosa        0.333333\n",
      "Iris-versicolor    0.333333\n",
      "Iris-virginica     0.333333\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# View frequency distribution of categorical variables\n",
    "for var in categorical: \n",
    "    print(df[var].value_counts()/float(len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'], dtype=object)"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check labels in class variable\n",
    "df['class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "Iris-setosa        50\n",
       "Iris-versicolor    50\n",
       "Iris-virginica     50\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check frequency distribution of values in native_country variable\n",
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[categorical].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class  contains  3  labels\n"
     ]
    }
   ],
   "source": [
    "# Check for cardinality in categorical variables\n",
    "for var in categorical:\n",
    "    print(var, ' contains ', len(df[var].unique()), ' labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4 numerical variables\n",
      "\n",
      "The numerical variables are : ['sepal length', 'sepal width', 'petal length', 'petal width']\n"
     ]
    }
   ],
   "source": [
    "# find numerical variables\n",
    "numerical = [var for var in df.columns if df[var].dtype!='O']\n",
    "\n",
    "print('There are {} numerical variables\\n'.format(len(numerical)))\n",
    "print('The numerical variables are :', numerical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length</th>\n",
       "      <th>sepal width</th>\n",
       "      <th>petal length</th>\n",
       "      <th>petal width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length  sepal width  petal length  petal width\n",
       "0           5.1          3.5           1.4          0.2\n",
       "1           4.9          3.0           1.4          0.2\n",
       "2           4.7          3.2           1.3          0.2\n",
       "3           4.6          3.1           1.5          0.2\n",
       "4           5.0          3.6           1.4          0.2"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the numerical variables\n",
    "df[numerical].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sepal length    0\n",
       "sepal width     0\n",
       "petal length    0\n",
       "petal width     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check missing values in numerical variables\n",
    "df[numerical].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sepal length    0\n",
       "sepal width     0\n",
       "petal length    0\n",
       "petal width     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for negative values in numerical variables\n",
    "df[numerical][df[numerical] < 0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the dataset to ensure randomness\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare feature vector and target variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split features (X) and target (y)\n",
    "X = df.iloc[:, :-1].values  # All columns except the last one as features\n",
    "y = df.iloc[:, -1].values   # The last column as target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into separate training and test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the train-test split ratio\n",
    "train_ratio = 0.7  # 70% training, 30% testing\n",
    "\n",
    "# Calculate the split index\n",
    "split_index = int(len(X) * train_ratio)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test = X[:split_index], X[split_index:]\n",
    "y_train, y_test = y[:split_index], y[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((105, 4), (45, 4))"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the shape of X_train and X_test\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((105,), (45,))"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the shape of y_train and y_test\n",
    "\n",
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:\n",
      " [[6.1 2.8 4.7 1.2]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.1 3.5 1.4 0.2]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [5.  2.  3.5 1. ]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [6.  3.  4.8 1.8]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.  2.2 4.  1. ]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [6.7 3.  5.  1.7]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [6.  2.2 5.  1.5]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.3 3.4 5.6 2.4]]\n",
      "y_train:\n",
      " ['Iris-versicolor' 'Iris-setosa' 'Iris-virginica' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-setosa' 'Iris-versicolor' 'Iris-virginica'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-virginica' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-versicolor'\n",
      " 'Iris-virginica' 'Iris-versicolor' 'Iris-versicolor' 'Iris-virginica'\n",
      " 'Iris-setosa' 'Iris-virginica' 'Iris-setosa' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-virginica' 'Iris-virginica' 'Iris-virginica'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-versicolor'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-virginica' 'Iris-versicolor'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-virginica'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-versicolor' 'Iris-virginica' 'Iris-virginica' 'Iris-versicolor'\n",
      " 'Iris-virginica' 'Iris-versicolor' 'Iris-virginica' 'Iris-versicolor'\n",
      " 'Iris-setosa' 'Iris-virginica' 'Iris-versicolor' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-versicolor' 'Iris-virginica'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-versicolor' 'Iris-setosa'\n",
      " 'Iris-versicolor' 'Iris-virginica' 'Iris-setosa' 'Iris-versicolor'\n",
      " 'Iris-virginica' 'Iris-setosa' 'Iris-virginica' 'Iris-virginica'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-virginica' 'Iris-versicolor'\n",
      " 'Iris-setosa' 'Iris-versicolor' 'Iris-virginica' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-versicolor' 'Iris-versicolor' 'Iris-setosa'\n",
      " 'Iris-virginica' 'Iris-setosa' 'Iris-setosa' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-virginica' 'Iris-versicolor' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-versicolor' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-virginica' 'Iris-virginica' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-versicolor' 'Iris-virginica']\n"
     ]
    }
   ],
   "source": [
    "# Outputs ready for Naive Bayes implementation\n",
    "print(\"X_train:\\n\", X_train)\n",
    "print(\"y_train:\\n\", y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_ How to build the Naive Bayes from Scratch _**\n",
    "\n",
    "Bayes' Theorem\n",
    "\n",
    "P(A|B) = P(B|A) \\* P(A) / P(B)\n",
    "\n",
    "The probability of event A, given another event B, can be calculated as above formula.\n",
    "\n",
    "Transfer this to our case, into class Lables and Features, then we can say:\n",
    "\n",
    "P(y|X) = P(X|y) \\* P(y) / P(X)\n",
    "\n",
    "y = class lables that we want to predict\n",
    "X = feature vector => X = {x1, x2, ..., xn}\n",
    "\n",
    "Assume that features are mutually independent.\n",
    "\n",
    "P(y|X) = P(x1|y) _ P(x2|y) _ ... _ P(xn|y) _ P(y) / P(X)\n",
    "\n",
    "We want to select class with highest posterior probability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        self._classes = np.unique(y)\n",
    "        n_classes = len(self._classes)\n",
    "\n",
    "        # calculate mean, var, and prior for each class\n",
    "        self._mean = np.zeros((n_classes, n_features), dtype=np.float64)\n",
    "        self._var = np.zeros((n_classes, n_features), dtype=np.float64)\n",
    "        self._priors =  np.zeros(n_classes, dtype=np.float64)\n",
    "\n",
    "        for idx, c in enumerate(self._classes):\n",
    "            X_c = X[y == c]\n",
    "            self._mean[idx, :] = X_c.mean(axis=0)\n",
    "            self._var[idx, :] = X_c.var(axis=0)\n",
    "            self._priors[idx] = X_c.shape[0] / float(n_samples)\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = [self._predict(x) for x in X]\n",
    "        return np.array(y_pred)\n",
    "    \n",
    "    def _predict(self, x):\n",
    "        posteriors = []\n",
    "\n",
    "        # calculate posterior probability for each class\n",
    "        for idx, c in enumerate(self._classes):\n",
    "            prior = np.log(self._priors[idx])\n",
    "            class_conditional = np.sum(np.log(self._pdf(idx, x)))\n",
    "            posterior = prior + class_conditional\n",
    "            posteriors.append(posterior)\n",
    "        \n",
    "        # return class with highest posterior probability\n",
    "        return self._classes[np.argmax(posteriors)]\n",
    "    \n",
    "    def _pdf(self, class_idx, x):\n",
    "        mean = self._mean[class_idx]\n",
    "        var = self._var[class_idx]\n",
    "        numerator = np.exp(- (x-mean)**2 / (2 * var))\n",
    "        denominator = np.sqrt(2 * np.pi * var)\n",
    "        return numerator / denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    accuracy = np.sum(y_true == y_pred) / len(y_true)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes classification accuracy: 0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "nb = NaiveBayes()\n",
    "nb.fit(X_train, y_train)\n",
    "predictions = nb.predict(X_test)\n",
    "\n",
    "print('Naive Bayes classification accuracy:', accuracy(y_test, predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
